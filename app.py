import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, roc_curve, auc, confusion_matrix
import time

# --- Configuration de la page Streamlit ---
st.set_page_config(
    layout="wide",
    page_title="Pipeline ML : D√©tection de Maladies Cardiovasculaires",
    initial_sidebar_state="expanded"
)

# --- D√©finition des colonnes (Bas√© sur un jeu de donn√©es standard) ---
NUM_COLS = ['Age', 'RestingBP', 'Cholesterol', 'MaxHR', 'Oldpeak']
CAT_COLS = ['Sex', 'ChestPainType', 'FastingBS', 'RestingECG', 'ExerciseAngina', 'ST_Slope']
TARGET_COL = 'HeartDisease' # Doit contenir 0 ou 1

# --- 0. Chargement des Donn√©es (Avec option d'upload) ---
@st.cache_data(show_spinner="Chargement ou g√©n√©ration des donn√©es...")
def load_and_prepare_data(uploaded_file):
    """Charge les donn√©es du fichier CSV ou g√©n√®re des donn√©es factices si aucun fichier n'est fourni."""
    if uploaded_file is not None:
        try:
            df = pd.read_csv(uploaded_file)
            st.sidebar.success(f"Fichier '{uploaded_file.name}' charg√© avec succ√®s. {df.shape[0]} lignes.")
            
            # V√©rification des colonnes essentielles
            required_cols = NUM_COLS + CAT_COLS + [TARGET_COL]
            if not all(col in df.columns for col in required_cols):
                st.error("Le fichier CSV ne contient pas les colonnes attendues (HeartDisease, Age, Cholesterol, etc.). Utilisation des donn√©es factices en remplacement.")
                df = generate_dummy_data()
            else:
                # S'assurer que la cible est bien binaire et mapp√©e pour la visualisation
                df[TARGET_COL] = df[TARGET_COL].astype(str).str.replace(r'\.0$', '', regex=True).astype(int)
        except Exception as e:
            st.error(f"Erreur de chargement ou de conversion des donn√©es : {e}. Utilisation des donn√©es factices.")
            df = generate_dummy_data()
    else:
        df = generate_dummy_data()
    
    # Mappage de la variable cible pour une meilleure visualisation
    df[TARGET_COL] = df[TARGET_COL].map({1: 'Malade', 0: 'Sain'})
    
    return df

def generate_dummy_data():
    """Cr√©e des donn√©es factices simulant un jeu de donn√©es de maladie cardiaque (pour la d√©mo)."""
    N = 918
    age = np.random.randint(20, 80, N)
    resting_bp = np.random.randint(90, 200, N)
    cholesterol = np.random.randint(100, 400, N)
    max_hr = np.random.randint(60, 200, N)
    
    risk_score = (age / 80) + (cholesterol / 400) + (resting_bp / 200) + (np.random.rand(N) * 0.5)
    heart_disease = (risk_score > np.percentile(risk_score, 45)).astype(int) 

    data = {
        'Age': age,
        'Sex': np.random.choice(['M', 'F'], N, p=[0.7, 0.3]),
        'ChestPainType': np.random.choice(['ATA', 'ASY', 'NAP', 'TA'], N),
        'RestingBP': resting_bp,
        'Cholesterol': cholesterol,
        'FastingBS': np.random.choice([0, 1], N, p=[0.8, 0.2]),
        'RestingECG': np.random.choice(['Normal', 'ST', 'LVH'], N),
        'MaxHR': max_hr,
        'ExerciseAngina': np.random.choice(['Y', 'N'], N),
        'Oldpeak': np.random.uniform(0.0, 4.0, N),
        'ST_Slope': np.random.choice(['Up', 'Flat', 'Down'], N),
        'HeartDisease': heart_disease
    }
    st.sidebar.warning("Aucun fichier 'heart.csv' charg√©. Utilisation des donn√©es factices.")
    return pd.DataFrame(data)

# --- Barre lat√©rale pour l'Upload ---
st.sidebar.title("Configuration des Donn√©es")
uploaded_file = st.sidebar.file_uploader("Veuillez charger 'heart.csv'", type=["csv"]) # C'est ici que vous chargez votre fichier

df = load_and_prepare_data(uploaded_file)

st.title("ü©∫ Pipeline de D√©tection des Maladies Cardiovasculaires (MCV)")
st.caption("Ce tableau de bord simule un projet de Machine Learning complet en 9 √©tapes.")


# --- Structure du Tableau de Bord par Onglets ---
tab1, tab2, tab3, tab4, tab56, tab7, tab8, tab9 = st.tabs([
    "1. Exploration des Donn√©es", 
    "2. Visualisation (Distributions)", 
    "3. Matrice de Corr√©lation", 
    "4. Pr√©traitement des Donn√©es", 
    "5 Mod√©lisation et √âvaluation", 
    "7. Visualisation des R√©sultats (ROC)", 
    "8. Optimisation (Random Forest)", 
    "9. Conclusion"
])

# ==============================================================================
# √âTAPE 1 : EXPLORATION DES DONN√âES
# ==============================================================================
with tab1:
    st.header("Exploration des Donn√©es (EDA)")
    st.markdown("Aper√ßu g√©n√©ral du jeu de donn√©es, de sa structure et des types de variables.")

    col1, col2, col3 = st.columns(3)
    with col1:
        st.subheader("Dimensions")
        st.info(f"Lignes: **{df.shape[0]}** | Colonnes: **{df.shape[1]}**")
    with col2:
        st.subheader("Variables Num√©riques")
        st.info(f"Total: **{len(NUM_COLS)}** ({', '.join(NUM_COLS)})")
    with col3:
        st.subheader("Variables Cat√©gorielles")
        st.info(f"Total: **{len(CAT_COLS)}** ({', '.join(CAT_COLS)})")

    st.subheader("Aper√ßu du DataFrame")
    st.dataframe(df.head())

    st.subheader("Statistiques Descriptives des Variables Num√©riques")
    st.dataframe(df[NUM_COLS].describe().T)

# ==============================================================================
# √âTAPE 2 : VISUALISATION 1 - DISTRIBUTIONS
# ==============================================================================
with tab2:
    st.header("Visualisation 1 - Distribution des Variables")
    st.markdown("Analyse de la variable cible et des distributions cl√©s.")

    # Distribution de la variable cible (HeartDisease)
    st.subheader("Distribution de la Variable Cible (HeartDisease)")
    fig_target = px.pie(
        df, 
        names=TARGET_COL, 
        title='R√©partition des Cas de Maladie Cardiovasculaire',
        color_discrete_sequence=['red', 'blue']
    )
    st.plotly_chart(fig_target, use_container_width=True)

    col_a, col_b = st.columns(2)

    # Distribution par √Çge
    with col_a:
        st.subheader("Distribution par √Çge et √âtat de Sant√©")
        fig_age = px.histogram(
            df, 
            x='Age', 
            color=TARGET_COL, 
            marginal="box", 
            nbins=30, 
            title="Distribution de l'√Çge par √âtat MCV",
            color_discrete_map={'Malade': 'red', 'Sain': 'blue'}
        )
        st.plotly_chart(fig_age, use_container_width=True)

    # Distribution par Sexe
    with col_b:
        st.subheader("Distribution par Sexe")
        sex_counts = df.groupby(['Sex', TARGET_COL]).size().reset_index(name='Count')
        fig_sex = px.bar(
            sex_counts, 
            x='Sex', 
            y='Count', 
            color=TARGET_COL, 
            barmode='group', 
            title="Cas de MCV par Sexe",
            color_discrete_map={'Malade': 'red', 'Sain': 'blue'}
        )
        st.plotly_chart(fig_sex, use_container_width=True)

    # Distribution par Type de Douleur Thoracique
    st.subheader("Distribution par Type de Douleur Thoracique")
    cp_counts = df.groupby(['ChestPainType', TARGET_COL]).size().reset_index(name='Count')
    fig_cp = px.bar(
        cp_counts, 
        x='ChestPainType', 
        y='Count', 
        color=TARGET_COL, 
        barmode='group', 
        title="Cas de MCV par Type de Douleur Thoracique",
        color_discrete_map={'Malade': 'red', 'Sain': 'blue'}
    )
    st.plotly_chart(fig_cp, use_container_width=True)


# ==============================================================================
# √âTAPE 3 : MATRICE DE CORR√âLATION
# ==============================================================================
with tab3:
    st.header("Matrice de Corr√©lation")
    st.markdown("Visualisation des relations lin√©aires entre toutes les variables (apr√®s encodage simple pour la corr√©lation).")

    # Pr√©paration des donn√©es pour la corr√©lation (encodage simple)
    df_corr = df.copy()
    # Convertir la cible et les colonnes cat√©gorielles en num√©rique pour le calcul
    df_corr[TARGET_COL] = df_corr[TARGET_COL].map({'Malade': 1, 'Sain': 0})
    # Encodage des colonnes cat√©gorielles
    df_corr = pd.get_dummies(df_corr, columns=CAT_COLS, drop_first=True)
    
    st.subheader("Heatmap de Corr√©lation (Num√©rique + Cat√©gorielle Encod√©e)")
    
    try:
        corr = df_corr.corr()
        # Filtrer pour ne montrer que les corr√©lations > |0.1| pour plus de clart√©
        corr_filtered = corr[corr.abs() > 0.1]
        
        fig_corr, ax = plt.subplots(figsize=(12, 10))
        sns.heatmap(
            corr_filtered, 
            annot=True, 
            cmap="coolwarm", 
            fmt=".2f", 
            linewidths=.5,
            cbar_kws={'label': 'Coefficient de Corr√©lation'},
            ax=ax
        )
        ax.set_title("Matrice de Corr√©lation (Coefficients > |0.1|)")
        st.pyplot(fig_corr)
    except Exception as e:
        st.error(f"Erreur lors du calcul de la corr√©lation : {e}")

# ==============================================================================
# √âTAPE 4 : PR√âTRAITEMENT DES DONN√âES
# ==============================================================================
@st.cache_data(show_spinner="Pr√©traitement des donn√©es en cours...")
def preprocess_data(data):
    """Effectue le pr√©traitement: Encodage et Mise √† l'√©chelle."""
    # Retirer les colonnes non n√©cessaires si elles sont apparues
    try:
        X = data.drop(TARGET_COL, axis=1)
        # Assurer que y est la version num√©rique pour l'entra√Ænement
        y = data[TARGET_COL].map({'Malade': 1, 'Sain': 0}) 
    except Exception as e:
        st.error(f"Erreur de pr√©paration des donn√©es pour l'entra√Ænement : {e}")
        return pd.DataFrame(), pd.Series(), None

    # D√©finition du pr√©processeur
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', StandardScaler(), NUM_COLS),
            ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), CAT_COLS)
        ],
        remainder='passthrough'
    )
    
    X_processed = preprocessor.fit_transform(X)
    
    # R√©cup√©rer les noms de colonnes pour X_processed
    feature_names = preprocessor.get_feature_names_out()
    X_processed_df = pd.DataFrame(X_processed, columns=feature_names)
    
    return X_processed_df, y, preprocessor

# ==============================================================================
# √âTAPE 5 & 6 : CONSTRUCTION, ENTRA√éNEMENT ET √âVALUATION DES MOD√àLES
# ==============================================================================
@st.cache_data(show_spinner="Entra√Ænement et √©valuation des mod√®les...")
def train_and_evaluate_models(X, y):
    """S√©pare les donn√©es, entra√Æne plusieurs mod√®les et retourne les r√©sultats."""
    if X.empty or y.empty:
        return pd.DataFrame(), [], None, None, None, None

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)
    
    models = {
        "Logistic Regression": LogisticRegression(random_state=42, max_iter=1000),
        "Decision Tree": DecisionTreeClassifier(random_state=42),
        "Random Forest": RandomForestClassifier(random_state=42),
        "Support Vector Machine": SVC(probability=True, random_state=42)
    }
    
    results = []
    
    for name, model in models.items():
        start_time = time.time()
        model.fit(X_train, y_train)
        end_time = time.time()
        
        y_pred = model.predict(X_test)
        y_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, "predict_proba") else [0] * len(y_test)
        
        accuracy = accuracy_score(y_test, y_pred)
        fpr, tpr, _ = roc_curve(y_test, y_proba)
        roc_auc = auc(fpr, tpr)
        
        results.append({
            'Mod√®le': name,
            'Accuracy': accuracy,
            'ROC AUC': roc_auc,
            'Temps d\'Entra√Ænement (s)': end_time - start_time,
            'y_proba': y_proba,
            'fpr': fpr,
            'tpr': tpr,
            'Model Instance': model
        })

    results_df = pd.DataFrame([
        {'Mod√®le': r['Mod√®le'], 'Accuracy': f"{r['Accuracy']:.4f}", 'ROC AUC': f"{r['ROC AUC']:.4f}", 'Temps (s)': f"{r['Temps d\'Entra√Ænement (s)']:.4f}"} 
        for r in results
    ])
    
    return results_df, results, X_test, y_test, X_train, y_train

# Application des √©tapes 4, 5 et 6 
X_processed, y, preprocessor = preprocess_data(df)
results_df, results_data, X_test, y_test, X_train, y_train = train_and_evaluate_models(X_processed, y)


with tab4:
    st.header(" Pr√©traitement des Donn√©es")
    st.markdown("Pr√©paration du jeu de donn√©es pour l'entra√Ænement : Standardisation des variables num√©riques et Encodage One-Hot des variables cat√©gorielles.")
    
    st.subheader("Transformations Appliqu√©es")
    st.write("Variables Num√©riques:", NUM_COLS, "‚Üí **StandardScaler** (Mise √† l'√©chelle)")
    st.write("Variables Cat√©gorielles:", CAT_COLS, "‚Üí **OneHotEncoder** (Cr√©ation de variables binaires)")
    
    if not X_processed.empty:
        st.subheader("Statistiques Post-Pr√©traitement")
        st.info(f"Dimensions de l'ensemble de fonctionnalit√©s (X) apr√®s encodage: **{X_processed.shape}**")
        st.info(f"Dimensions de la variable cible (y): **{y.shape}**")
        
        with st.expander("Aper√ßu des Donn√©es Pr√©trait√©es (5 premi√®res lignes)"):
            st.dataframe(X_processed.head())
    else:
        st.warning("Pr√©traitement impossible. Veuillez v√©rifier le chargement des donn√©es.")


with tab56:
    st.header("Construction, Entra√Ænement et √âvaluation des Mod√®les")
    st.markdown("Quatre mod√®les de classification ont √©t√© entra√Æn√©s et √©valu√©s sur la pr√©cision (Accuracy) et l'aire sous la courbe ROC (ROC AUC).")
    
    if not results_df.empty:
        st.subheader("Performance des Mod√®les de Classification")
        
        st.dataframe(results_df.sort_values(by='ROC AUC', ascending=False).reset_index(drop=True))
        
        # Affichage du rapport de classification du meilleur mod√®le
        best_model_name = results_df.sort_values(by='ROC AUC', ascending=False).iloc[0]['Mod√®le']
        best_result = next(r for r in results_data if r['Mod√®le'] == best_model_name)
        
        st.subheader(f"Rapport de Classification D√©taill√© pour : {best_model_name}")
        st.text(classification_report(y_test, best_result['Model Instance'].predict(X_test), target_names=['Sain (0)', 'Malade (1)'], zero_division=0))

        # Matrice de confusion
        st.subheader("Matrice de Confusion du Meilleur Mod√®le")
        cm = confusion_matrix(y_test, best_result['Model Instance'].predict(X_test))
        fig_cm, ax = plt.subplots(figsize=(6, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Sain (0)', 'Malade (1)'], yticklabels=['Sain (0)', 'Malade (1)'], ax=ax)
        ax.set_xlabel('Pr√©diction')
        ax.set_ylabel('Valeur R√©elle')
        st.pyplot(fig_cm)
    else:
        st.warning("Aucun r√©sultat d'entra√Ænement. Veuillez v√©rifier le pr√©traitement des donn√©es.")

# ==============================================================================
# √âTAPE 7 : VISUALISATION DES R√âSULTATS (Courbes ROC)
# ==============================================================================
with tab7:
    st.header("Visualisation des R√©sultats - Courbes ROC")
    st.markdown("La courbe ROC (Receiver Operating Characteristic) et l'AUC montrent la capacit√© de chaque mod√®le √† distinguer les cas 'Malade' des cas 'Sain'.")
    
    if results_data and not results_df.empty:
        fig_roc, ax_roc = plt.subplots(figsize=(10, 8))
        
        # Trac√© de la ligne de base (al√©atoire)
        ax_roc.plot([0, 1], [0, 1], 'k--', label='Al√©atoire (AUC = 0.50)')

        # Trac√© des courbes pour chaque mod√®le
        for r in results_data:
            ax_roc.plot(r['fpr'], r['tpr'], label=f"{r['Mod√®le']} (AUC = {r['ROC AUC']:.4f})")
        
        ax_roc.set_xlabel('Taux de Faux Positifs (FPR)')
        ax_roc.set_ylabel('Taux de Vrais Positifs (TPR)')
        ax_roc.set_title('Courbes ROC Multi-Mod√®les')
        ax_roc.legend(loc="lower right")
        ax_roc.grid(True)
        st.pyplot(fig_roc)
    else:
        st.warning("Impossible de tracer les courbes ROC. V√©rifiez les √©tapes pr√©c√©dentes.")

# ==============================================================================
# √âTAPE 8 : OPTIMISATION DU MEILLEUR MOD√àLE (Random Forest)
# ==============================================================================
@st.cache_data(show_spinner="Optimisation du Random Forest par GridSearchCV...")
def optimize_random_forest(X_train, y_train):
    """Optimisation des hyperparam√®tres du Random Forest."""
    rf_model = RandomForestClassifier(random_state=42)
    
    # Espace de recherche r√©duit pour un temps d'ex√©cution rapide dans Streamlit
    param_grid = {
        'n_estimators': [100, 200],
        'max_depth': [5, 10, None],
        'min_samples_split': [2, 5]
    }
    
    grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, scoring='roc_auc', verbose=1, n_jobs=-1)
    grid_search.fit(X_train, y_train)
    
    return grid_search.best_estimator_, grid_search.best_params_, grid_search.best_score_

with tab8:
    st.header(" Optimisation du Meilleur Mod√®le (Random Forest)")
    st.markdown("Le mod√®le Random Forest est optimis√© en utilisant `GridSearchCV` pour trouver la meilleure combinaison d'hyperparam√®tres.")
    
    if not X_train.empty:
        best_rf_model, best_params, best_score = optimize_random_forest(X_train, y_train)

        st.subheader("Meilleurs Hyperparam√®tres Trouv√©s")
        st.json(best_params)
        
        st.subheader("Score (ROC AUC) du Mod√®le Optimis√©")
        st.success(f"ROC AUC sur l'ensemble d'entra√Ænement (Cross-Validation) : **{best_score:.4f}**")
        
        # √âvaluation sur l'ensemble de test avec le mod√®le optimis√©
        y_pred_opt = best_rf_model.predict(X_test)
        y_proba_opt = best_rf_model.predict_proba(X_test)[:, 1]
        accuracy_opt = accuracy_score(y_test, y_pred_opt)
        roc_auc_opt = auc(*roc_curve(y_test, y_proba_opt)[:2])

        st.subheader("Performance sur l'Ensemble de Test (Mod√®le Optimis√©)")
        col_opt_1, col_opt_2 = st.columns(2)
        col_opt_1.metric("Accuracy Optimis√©e", f"{accuracy_opt:.4f}")
        col_opt_2.metric("ROC AUC Optimis√©", f"{roc_auc_opt:.4f}")

        with st.expander("Rapport de Classification du Mod√®le Optimis√©"):
            st.text(classification_report(y_test, y_pred_opt, target_names=['Sain (0)', 'Malade (1)'], zero_division=0))
    else:
        st.warning("Impossible de proc√©der √† l'optimisation. V√©rifiez l'entra√Ænement des mod√®les.")

# ==============================================================================
# √âTAPE 9 : CONCLUSION
# ==============================================================================
with tab9:
    st.header(" Conclusion du Projet")
    st.markdown("Synth√®se des r√©sultats et prochaines √©tapes sugg√©r√©es.")
    
    if not results_df.empty:
        best_model_name_final = results_df.sort_values(by='ROC AUC', ascending=False).iloc[0]['Mod√®le']
        roc_auc_max = float(results_df['ROC AUC'].max())
        
        st.info(f"""
            ### R√©capitulatif
            * **Donn√©es** : Utilisation des donn√©es {'charg√©es' if uploaded_file else 'factices g√©n√©r√©es'}.
            * **Objectif** : D√©tecter la maladie cardiovasculaire (MCV).
            * **Meilleur Mod√®le Initial** : Le **{best_model_name_final}** a montr√© la meilleure performance avec un ROC AUC de **{roc_auc_max:.4f}**.
            * **Optimisation** : Apr√®s l'optimisation des hyperparam√®tres du Random Forest (si l'√©tape 8 a √©t√© ex√©cut√©e), le mod√®le a atteint un ROC AUC sur l'ensemble de test de **{roc_auc_opt:.4f}**.
            
            ### Prochaines √âtapes
            1.  **Ing√©nierie de Fonctionnalit√©s (Feature Engineering)** : Cr√©er des variables plus pr√©dictives, comme l'indice de masse corporelle (IMC).
            2.  **Validation Externe** : Tester le mod√®le optimis√© sur un jeu de donn√©es externe (non vu) pour confirmer sa g√©n√©ralisation.
            3.  **Interpr√©tabilit√© (SHAP/LIME)** : Comprendre quelles variables (√¢ge, cholest√©rol, etc.) contribuent le plus √† chaque pr√©diction.
        """)
    else:
        st.warning("Synth√®se impossible. Veuillez vous assurer que les donn√©es ont √©t√© charg√©es et les mod√®les entra√Æn√©s.")